# Acceleration-based-action-detection

This project focuses on detecting user actions based on acceleration data and gyryscope data collected from mobile device sensors. The system processes raw accelerometer input to classify physical actions (e.g., walking, running, standing, falling) in real time. The project consists of:

A Python module for data preprocessing, visualization, feature engineering, and training/testing an ML model.

A Kotlin-based Android app for collecting sensor data and deploying the model for on-device prediction.